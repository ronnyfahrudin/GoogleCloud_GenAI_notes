{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "om0L7SpIkezD"
   },
   "source": [
    "# Using PaLM to Cluster Products Based on Descriptions\n",
    "\n",
    "In this lab, you're going to use a list of product descriptions to create a model that will cluster products together. To train the clustering model, you need to find the meaning of the text in the descriptions. You'll take advantage of the language understanding of the PaLM model to generate the embedded meanings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcKYLauBqxKT",
    "tags": []
   },
   "source": [
    "## Setup\n",
    "To access the PaLM Embeddings, you need to set up the client to access Vertex AI. Start by installing one of the latest versions of the Python client library.\n",
    "\n",
    "All of the imports will be done up front to keep the notebook tidy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "rahbv6G3A5u9",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "d3f51d3f-1230-430b-f539-e7d3c6090d7f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform>=1.27 in /opt/conda/lib/python3.9/site-packages (1.41.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.27) (1.34.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/conda/lib/python3.9/site-packages (from google-cloud-aiplatform>=1.27) (1.23.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.9/site-packages (from google-cloud-aiplatform>=1.27) (3.19.6)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.9/site-packages (from google-cloud-aiplatform>=1.27) (23.2)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.9/site-packages (from google-cloud-aiplatform>=1.27) (2.11.0)\n",
      "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.9/site-packages (from google-cloud-aiplatform>=1.27) (3.17.2)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.9/site-packages (from google-cloud-aiplatform>=1.27) (1.12.0)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.9/site-packages (from google-cloud-aiplatform>=1.27) (2.0.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.9/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.27) (1.62.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /opt/conda/lib/python3.9/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.27) (1.35.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.9/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.27) (2.31.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.27) (1.48.1)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.27) (1.48.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform>=1.27) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.9/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform>=1.27) (2.7.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.9/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform>=1.27) (2.8.2)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.9/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform>=1.27) (0.12.7)\n",
      "Requirement already satisfied: numpy>=1.14 in /opt/conda/lib/python3.9/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform>=1.27) (1.19.5)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.27) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.27) (0.3.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.27) (69.0.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.27) (1.15.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.27) (4.9)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.9/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform>=1.27) (1.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.27) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.27) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.27) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.27) (2024.2.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.27) (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install \"google-cloud-aiplatform>=1.27\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Yj86jOepszm"
   },
   "source": [
    "\n",
    "### Installs\n",
    "Make sure we have a new enough version of the Vertex AI Python client library to use the `textembeddings-gecko` model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the install, we need to restart the kernel to use the new library version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IoiMMtRdlj-p"
   },
   "source": [
    "### Imports\n",
    "Import all of the modules needed for the notebook.\n",
    "\n",
    "Most modules in the Python client library belong to the package `google.cloud`, but Vertex AI is an exception.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "TK8osmKGB90I",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import google.auth\n",
    "from google.cloud import storage\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from typing import Generator, List, Optional, Tuple\n",
    "import functools\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import pickle\n",
    "from urllib.request import urlopen\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0kIBlZamszU"
   },
   "source": [
    "### User Authentication\n",
    "If you are using Colab, uncomment this cell and run it to authenticate as your user for Google Cloud.\n",
    "\n",
    "Shortcut: Select the cell contents and press `Ctrl/Cmd + /`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "z0pHFht6Dyz9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nPKRJx2n2V0"
   },
   "source": [
    "Run the cell below to retrieve the credentials for intializing access to Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4IJy1q43moMm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "credentials, _ = google.auth.default()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpV7k9eJnB3g"
   },
   "source": [
    "### Client setup\n",
    "\n",
    "Configure your project ID in `MY_PROJECT`.\n",
    "\n",
    "If you want to use a specific Vertex AI location, set it as `VERTEX_LOCATION`. We'll default to us-central1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "uZvSlFSMpbWs",
    "tags": []
   },
   "outputs": [],
   "source": [
    "MY_PROJECT='qwiklabs-gcp-03-282f7cda83db'\n",
    "VERTEX_LOCATION='us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "20jsc9ZlBLUb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertexai.init(\n",
    "    project=MY_PROJECT,\n",
    "    location=VERTEX_LOCATION,\n",
    "    #credentials set above\n",
    "    credentials=credentials\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVceXVB5rx9I"
   },
   "source": [
    "## Data\n",
    "The product description data we are using was gathered for the paper\n",
    "\n",
    "**Justifying recommendations using distantly-labeled reviews and fined-grained aspects**\\\n",
    "Jianmo Ni, Jiacheng Li, Julian McAuley\\\n",
    "_Empirical Methods in Natural Language Processing (EMNLP)_, 2019\\\n",
    "[pdf](http://cseweb.ucsd.edu/~jmcauley/pdfs/emnlp19a.pdf)\n",
    "\n",
    "This [dataset](https://cseweb.ucsd.edu/~jmcauley/datasets/amazon_v2/index.html) includes many additional fields that you're not going to use, including reviews from users. To keep this lab more focused, the data has already been parsed and cleaned. We've taken a sample of 2,000 products each across 5 categories, for a total of 10,000 products. The clustering model you'll train will be used to attempt to rediscover those categories!\n",
    "\n",
    "The cleaned data only includes the name of the item and the description. This is formatted into a CSV file, which is hosted on Cloud Storage.\n",
    "\n",
    "The five original categories are as follows:\n",
    "* all beauty\n",
    "* appliances\n",
    "* musical instruments\n",
    "* pantry\n",
    "* software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "CL2wsxJjR9pA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "URL = 'https://storage.googleapis.com/cloud-training/specialized-training/model_garden/products.csv.gz'\n",
    "products_df = pd.read_csv(URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VoRsQQ7hFu_b"
   },
   "source": [
    "You can preview the data in the following cell. Verify that there are indeed 10,000 rows of data consisting of two columns: name and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Y3pvqtTWVi-j",
    "outputId": "f26aa7e4-7f84-42ee-eecf-8befdb558b43",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NAILTEK CITRA Formula 3 Protection for Dry, Br...</td>\n",
       "      <td>NAILTEK CITRA Formula #3 Protection for Dry, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wildberry Incense Sticks: Vanilla</td>\n",
       "      <td>Vanilla incense is smooth, creamy and delectable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wonder Pro Professional Red Rubber Sponge #010...</td>\n",
       "      <td>Wonder Pro Professional Red Sponges-2 pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ronson 2.75 oz(78 Gram) Butane Multi-Fill/12 Pk.</td>\n",
       "      <td>Fills up to 20 disposable lighters per bottle.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NUKSIT 10% Sulfur Ointment - Large tub 4oz, Po...</td>\n",
       "      <td>This 4 oz size is an excellent value. Swiss fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Mayo Clinic Family Health 3.0 (PC CD Jewel Case)</td>\n",
       "      <td>Mayo Clinic one of the most trusted names in m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>SecurErase 8: Permanently Erase Your Hard Drive</td>\n",
       "      <td>SecurErase overwrites the data that sits unuse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Finale 2008-2009 Tutorial DVD</td>\n",
       "      <td>156 videos with a running time of over 8.5 hou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Putt-Putt Joins the Circus - PC/Mac</td>\n",
       "      <td>Step Right Up!  Discover the Circus with Putt-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>KidSpeak: Spanish French German Italian Japane...</td>\n",
       "      <td>the most fun, most effective way for kids to l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   name  \\\n",
       "0     NAILTEK CITRA Formula 3 Protection for Dry, Br...   \n",
       "1                     Wildberry Incense Sticks: Vanilla   \n",
       "2     Wonder Pro Professional Red Rubber Sponge #010...   \n",
       "3      Ronson 2.75 oz(78 Gram) Butane Multi-Fill/12 Pk.   \n",
       "4     NUKSIT 10% Sulfur Ointment - Large tub 4oz, Po...   \n",
       "...                                                 ...   \n",
       "9995   Mayo Clinic Family Health 3.0 (PC CD Jewel Case)   \n",
       "9996    SecurErase 8: Permanently Erase Your Hard Drive   \n",
       "9997                      Finale 2008-2009 Tutorial DVD   \n",
       "9998                Putt-Putt Joins the Circus - PC/Mac   \n",
       "9999  KidSpeak: Spanish French German Italian Japane...   \n",
       "\n",
       "                                            description  \n",
       "0     NAILTEK CITRA Formula #3 Protection for Dry, B...  \n",
       "1     Vanilla incense is smooth, creamy and delectable.  \n",
       "2            Wonder Pro Professional Red Sponges-2 pack  \n",
       "3        Fills up to 20 disposable lighters per bottle.  \n",
       "4     This 4 oz size is an excellent value. Swiss fo...  \n",
       "...                                                 ...  \n",
       "9995  Mayo Clinic one of the most trusted names in m...  \n",
       "9996  SecurErase overwrites the data that sits unuse...  \n",
       "9997  156 videos with a running time of over 8.5 hou...  \n",
       "9998  Step Right Up!  Discover the Circus with Putt-...  \n",
       "9999  the most fun, most effective way for kids to l...  \n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "citgca62VrG3",
    "outputId": "a08fd0db-7a91-490f-eb71-1c15d540383c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(products_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fij3WI3p0dJ"
   },
   "source": [
    "## Embeddings Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhdpjoJfGKzb"
   },
   "source": [
    "With the product information loaded, you can now get the embeddings for the description. Start by loading the model. Check the model card in Model Garden for how to get started, or view the API documentation.\n",
    "\n",
    "[PaLM Text Embeddings Model Card](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/textembedding-gecko)\n",
    "\n",
    "[TexEmbeddingModel API](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai.language_models.TextEmbeddingModel)\n",
    "\n",
    "[TextEmbeddingModel code](https://github.com/googleapis/python-aiplatform/blob/main/vertexai/language_models/_language_models.py#L510)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "3ftbeq7vBRhC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYENqbBkHW1E"
   },
   "source": [
    "Confirm that we are using the model from Model Garden that we expect, which is the TextEmbeddingModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RGJv1qTbEqyR",
    "outputId": "8e8c863f-b43d-4c8b-b6ea-31c27fc00810",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vertexai.language_models.TextEmbeddingModel"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3hKDOiEGjeh"
   },
   "source": [
    "Let's try calling the model with a couple example sentences, just to see the basic process. We'll print the first 15 dimensions of each vector to see what the result looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bgt4XOgzDOmC",
    "outputId": "5dc9ca47-f7b9-4608-bcd9-c779d343c198",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03096592240035534, -0.029723884537816048, -0.02945883944630623, -0.001032328000292182, 0.0022590886801481247, 0.0031512489076703787, 0.013303607702255249, 0.04867033660411835, 0.010392100550234318, 0.02595921978354454, 0.01610957831144333, -0.01902991719543934, -0.010085889138281345, -0.04759019985795021, -0.006539858411997557]\n",
      "\n",
      "-----\n",
      "\n",
      "[0.03973103687167168, -0.006406881846487522, -0.017857957631349564, -0.036904141306877136, 0.026091644540429115, -0.05112924054265022, -0.00610671890899539, 0.04275573417544365, 0.024409454315900803, 0.0495748408138752, -0.0033980044536292553, 0.00596003420650959, -0.008513648062944412, -0.03448595106601715, 0.027761366218328476]\n",
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.get_embeddings([\"Dinner in New York City\", \"Dinner in Paris\"])\n",
    "for embedding in embeddings:\n",
    "    vector = embedding.values\n",
    "    print(vector[:15])\n",
    "    print('\\n-----\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ppUMX7zYG7ml",
    "outputId": "e7878f1b-141e-415f-8217-1d69d0c3e898",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response type: <class 'list'>\n",
      "Each response type: <class 'vertexai.language_models.TextEmbedding'>\n"
     ]
    }
   ],
   "source": [
    "print(f'Response type: {type(embeddings)}')\n",
    "print(f'Each response type: {type(embeddings[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hh6TJ-iVGz0Y"
   },
   "source": [
    "The Python client puts the responses from the model into a list in order of the requested sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zpm1RlMLHLqe",
    "outputId": "19e08bbd-91b3-432c-f178-4201ec4df49a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mgjOu2ieb7wz"
   },
   "source": [
    "The TextEmbeddings are a set of floating point values representing the 768 dimensions used by PaLM for understanding the meaning of text. Later, we'll convert these lists of floats to numpy ndarrays for easier use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_aH-3daHg2p",
    "outputId": "a071a97e-7226-417a-f6d4-480a5f0e03a1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values: 768\n",
      "Value type: <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "print(f'Values: {len(embeddings[0].values)}')\n",
    "print(f'Value type: {type(embeddings[0].values[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wL_f1-nH5Si"
   },
   "source": [
    "According to the [documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings#get_text_embeddings_for_a_snippet_of_text), the API has a limit of 5 input texts (product descriptions in our case) per API call. With a batch size of 5 and 10,000 product descriptions to embed, we'll need to make 2,000 calls to the API. It's time to turn the basic example into a function for more utility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71syMMrEXLu-"
   },
   "source": [
    "#### Function to call the model\n",
    "This function does what our basic example does, which is call the `get_embeddings` method to convert our text. It adds very basic error handling, which should be expanded for production use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "980yTXSPXCT2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define an embedding method that uses the model\n",
    "def encode_texts_to_embeddings(sentences: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        embeddings = model.get_embeddings(sentences)\n",
    "        return [embedding.values for embedding in embeddings]\n",
    "    except Exception:\n",
    "        return [None for _ in range(len(sentences))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ya9y9rXPKK5P"
   },
   "source": [
    "#### Define two more helper functions for converting text to embeddings\n",
    "\n",
    "- generate_batches:  This method splits `sentences` into batches of 5 before sending to the embedding API.\n",
    "- encode_text_to_embedding_batched: This method calls `generate_batches` to handle batching and then calls the embedding API via `encode_texts_to_embeddings`. It also handles rate-limiting using `time.sleep`. For production use cases, you would want a more sophisticated rate-limiting mechanism that takes retries into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "QfO_IE3cKOWn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generator function to yield batches of descriptions\n",
    "def generate_batches(\n",
    "    descriptions: List[str], batch_size: int\n",
    ") -> Generator[List[str], None, None]:\n",
    "    for i in range(0, len(descriptions), batch_size):\n",
    "        yield descriptions[i : i + batch_size]\n",
    "\n",
    "\n",
    "def encode_text_to_embedding_batched(\n",
    "    descriptions: List[str], api_calls_per_minute: int = 20, batch_size: int = 5\n",
    ") -> Tuple[List[bool], np.ndarray]:\n",
    "\n",
    "    embeddings_list: List[List[float]] = []\n",
    "\n",
    "    # Prepare the batches using a generator\n",
    "    batches = generate_batches(descriptions, batch_size)\n",
    "\n",
    "    seconds_per_job = 60 / api_calls_per_minute\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for batch in tqdm(\n",
    "            batches, total=math.ceil(len(descriptions) / batch_size), position=0\n",
    "        ):\n",
    "            futures.append(\n",
    "                executor.submit(functools.partial(encode_texts_to_embeddings), batch)\n",
    "            )\n",
    "            time.sleep(seconds_per_job)\n",
    "\n",
    "        for future in futures:\n",
    "            embeddings_list.extend(future.result())\n",
    "\n",
    "    is_successful = [\n",
    "        embedding is not None for sentence, embedding in zip(descriptions, embeddings_list)\n",
    "    ]\n",
    "    embeddings_list_successful = np.squeeze(\n",
    "        np.stack([embedding for embedding in embeddings_list if embedding is not None])\n",
    "    )\n",
    "    return is_successful, embeddings_list_successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpbR-pIxd0jw"
   },
   "source": [
    "#### Generate Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lkV9gat23jmc"
   },
   "source": [
    "To generate the embeddings, we will call the batch helper function. However, the Qwiklabs environment has a low rate quota, so this process will take a long time to complete. Luckily, an important principle of the embeddings is that they won't substantially change no matter when you do the conversion! We can compute the embeddings once, store them, then load them whenever we need them again.\n",
    "\n",
    "The below cell is the code for generating the embeddings. It is commented out since you won't be using it, but it does show you the process for your own use later! Make sure to change the `api_calls_per_minute` parameter based on [your own quota rate limit!](https://console.cloud.google.com/iam-admin/quotas?referrer=search&pageState=(%22allQuotasTable%22:(%22f%22:%22%255B%257B_22k_22_3A_22_22_2C_22t_22_3A10_2C_22v_22_3A_22_5C_22base_model_3Atextembedding-gecko_5C_22_22_2C_22s_22_3Atrue%257D%255D%22)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "639ed7d1fc2449419e9adfc1efbb9fa6",
      "48db3d8ca8d14e0ebef708aa4a270c22",
      "6c6e34ee0d0a4fb69c168b9b34738a73",
      "90cdce26d7834e9b81747b2d224e69e3",
      "f5c46ed3021a4db9a14ea5d10dcb0615",
      "366467fb9a6c409e9a2d0311d93b68fd",
      "54169e2dbec64f20b380de669b591d34",
      "0bb79938f69b41fe8b6976cd5bb7332d",
      "be1a4562bfde46ae8eea31b45e3f5f7a",
      "05e05253caba4266931b2c4d35b16944",
      "5797768f09414ed49d673fe0bb21573b"
     ]
    },
    "id": "XK_qEE1bWlxS",
    "outputId": "0582a89a-09e3-4fde-b6b7-30e3d9c59758",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# descriptions = products_df['description'].values.tolist()\n",
    "# response = encode_text_to_embedding_batched(descriptions, api_calls_per_minute=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "263Foe2v43bx"
   },
   "source": [
    "The full response is hosted on Cloud Storage so we can import it and pick up right where the previous cell would have left us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "e2Kl3jbI7Zuq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "URL = 'https://storage.googleapis.com/cloud-training/specialized-training/model_garden/embeddings-response.pkl'\n",
    "response = pickle.load(urlopen(URL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jMwOxSgiXsYz"
   },
   "source": [
    "The `response` created by the `encode_text_to_embeddings_batched` function is a Tuple of (List[bool], ndarray)\n",
    "\n",
    "The first tuple item represents whether the API call was successful or not. There should be an equal number of responses to the size of the original product description list (10,000). These should all be True to indicate we have embeddings for every description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JG3pK5F9Xmm_",
    "outputId": "929f87b3-ee7b-460d-b024-837fe337a3ea",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 0\n",
      "\ttype: <class 'list'>\n",
      "\tvalues: 10000\n",
      "All embeddings requests completed successfully: True\n"
     ]
    }
   ],
   "source": [
    "print('Item 0')\n",
    "print(f'\\ttype: {type(response[0])}')\n",
    "print(f'\\tvalues: {len(response[0])}')\n",
    "# Test to make sure all responses are True.\n",
    "print(f'All embeddings requests completed successfully: {all(response[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pSBtah4Bh4R"
   },
   "source": [
    "The second tuple item is a numpy ndarray of the 768-dimension embedding vectors provided by the model for each product description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0C60kW2N-2ft",
    "outputId": "11c9ce86-030b-475e-91ed-cfcd6c9e8379",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 1\n",
      "\ttype: <class 'numpy.ndarray'>\n",
      "\tshape: (10000, 768)\n",
      "\tvector data type: float64\n"
     ]
    }
   ],
   "source": [
    "print('Item 1')\n",
    "print(f'\\ttype: {type(response[1])}')\n",
    "print(f'\\tshape: {response[1].shape}')\n",
    "print(f'\\tvector data type: {response[1].dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Uxkd_JGEXgt"
   },
   "source": [
    "Even though the giant string of floating point numbers doesn't mean anything to us as humans, it's still interesting to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "SYZ5l-w6DXxz",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "4e45cb9f-9406-4854-8656-aefb564ad3db",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: \n",
      "NAILTEK CITRA Formula #3 Protection for Dry, Brittle Nails .47oz  Conditions brittle dry nails, replenishes the natural moisture of the nails and provides the hydration necessary to resist stress and enhance survivability.\n",
      "Embedding vector:\n",
      "[ 7.15385750e-03 -4.29799780e-02  1.26909539e-02  4.06474955e-02\n",
      "  3.32920589e-02 -3.13577242e-02  1.17542723e-03  4.91597764e-02\n",
      " -3.15157063e-02  2.28883326e-02 -1.06803495e-02 -2.03404780e-02\n",
      " -8.10595509e-03  5.78571521e-02 -2.30540130e-02  2.81607080e-03\n",
      " -3.40594761e-02  1.62891373e-02  5.20878360e-02 -2.91049127e-02\n",
      " -3.44198048e-02  1.58195440e-02  4.27926099e-03 -2.42937859e-02\n",
      " -4.03086506e-02 -1.00072347e-01  3.45601961e-02  3.35591137e-02\n",
      " -9.63283181e-02  1.69923436e-02  2.54319627e-02 -1.66077930e-02\n",
      "  7.08263554e-03 -4.55290545e-03  5.14889322e-02 -2.29180660e-02\n",
      " -3.43148340e-03  3.82181592e-02  1.08421817e-02  3.67002264e-02\n",
      "  5.52216880e-02  7.56995240e-03 -8.73890519e-03 -1.41722541e-02\n",
      " -4.04832661e-02 -3.24015990e-02 -7.56350011e-02  2.39020046e-02\n",
      " -6.76997332e-03 -9.74866375e-03 -3.09144659e-03 -8.20198096e-03\n",
      " -8.78797192e-03  5.25356224e-03 -4.00880650e-02  6.37247227e-03\n",
      " -1.26690902e-02 -5.48637845e-02  2.85913441e-02 -1.14145121e-02\n",
      " -4.38016024e-04 -5.15829958e-03 -3.19305174e-02 -5.57403453e-02\n",
      " -7.48969661e-03  3.76742445e-02  5.43452799e-02 -2.03219336e-02\n",
      " -1.20180601e-03  2.45732982e-02  7.84648769e-03  2.99184918e-02\n",
      "  2.31995285e-02 -1.51646798e-02 -8.76861857e-04  1.68948490e-02\n",
      "  1.32161370e-02  2.81438213e-02  1.23643251e-02 -6.71081394e-02\n",
      " -1.21048382e-02 -5.00531122e-02 -4.34477851e-02 -8.03929046e-02\n",
      " -1.86712835e-02  3.65783796e-02 -2.64646485e-02 -3.10300793e-02\n",
      " -7.68966042e-04  3.63071226e-02 -3.59919257e-02  6.17828546e-03\n",
      " -1.41045137e-03 -2.01929882e-02 -3.86741906e-02  5.92623139e-03\n",
      "  1.95174795e-02  5.37055358e-03 -2.22131331e-03 -2.18007155e-02\n",
      "  1.36325452e-02 -3.34311239e-02  4.01673801e-02 -8.41023494e-03\n",
      "  3.68116200e-02  9.83050466e-03  3.18114422e-02  7.46818446e-03\n",
      " -4.33059111e-02 -1.22805968e-01 -6.65923581e-02 -5.09762717e-03\n",
      " -2.30138358e-02  6.82830904e-03  2.66988650e-02 -3.42950970e-02\n",
      "  1.20293619e-02 -2.83188447e-02  6.15635477e-02  7.21685812e-02\n",
      " -2.80276351e-02  6.92750216e-02  3.21810246e-02  2.47066151e-02\n",
      " -2.07797885e-02  3.55372578e-02  2.72533949e-02 -4.25768449e-05\n",
      "  4.37692292e-02  3.68748978e-02  1.74076036e-02 -1.38463303e-02\n",
      "  7.39484429e-02 -1.24975713e-02  2.59856097e-02  6.43532276e-02\n",
      "  3.35766301e-02  1.28992815e-02 -1.00734821e-02  4.86534312e-02\n",
      " -5.26648462e-02 -1.42936474e-02 -2.00569369e-02  1.37840603e-02\n",
      "  3.07940356e-02 -2.06505265e-02  2.83510126e-02 -2.18098443e-02\n",
      " -8.33836421e-02 -3.26683261e-02  1.96780860e-02  1.53073333e-02\n",
      " -7.97305815e-03  3.42617221e-02  7.23749250e-02  2.18298435e-02\n",
      "  6.42678216e-02  4.42443676e-02 -6.54503107e-02 -2.80739572e-02\n",
      "  4.69970368e-02 -1.12361433e-02  5.67523250e-03  1.64357945e-02\n",
      "  3.38595249e-02  6.53763860e-03  7.83762857e-02 -1.26185119e-02\n",
      " -2.67220028e-02  3.81750949e-02  8.29688273e-03 -9.20319781e-02\n",
      "  3.66297923e-02 -5.56109436e-02  2.62444820e-02  2.60070469e-02\n",
      " -4.77129705e-02  3.29752043e-02 -2.56519951e-02 -3.43356766e-02\n",
      " -6.19077720e-02 -3.34390849e-02  2.14934386e-02  5.85399605e-02\n",
      " -5.72643913e-02  6.32184604e-03  2.60747019e-02 -6.38447478e-02\n",
      " -2.56581511e-02  5.07736616e-02 -2.12116651e-02  1.93865541e-02\n",
      "  4.61108424e-03 -8.64940211e-02  6.91532856e-03 -2.57368777e-02\n",
      "  9.37830135e-02 -1.74074143e-01 -4.93459404e-03  6.70488849e-02\n",
      " -3.73463775e-03 -1.68131012e-02  2.25029215e-02  3.64468955e-02\n",
      " -4.01022173e-02  1.59036852e-02 -5.19591831e-02  1.12744458e-02\n",
      "  4.97710332e-02 -3.68664041e-02  4.79280166e-02 -1.66661537e-03\n",
      "  6.42769039e-02  9.63094644e-04  2.59369481e-02 -3.68301873e-03\n",
      " -1.01978406e-02 -8.96316916e-02 -7.34064355e-02 -5.89544289e-02\n",
      " -6.45102840e-03 -3.04904720e-03  4.00747880e-02  3.71905454e-02\n",
      " -9.47782025e-03  1.94517225e-02  2.18461864e-02 -8.56475439e-03\n",
      "  5.41568175e-02  2.91419635e-03 -1.79809332e-02 -8.67587980e-03\n",
      " -5.44067211e-02 -3.74696888e-02 -6.43983576e-03  2.27882992e-02\n",
      "  2.26226263e-03 -1.32052228e-02 -2.49527469e-02 -1.30801778e-02\n",
      " -2.18608230e-02  7.94624835e-02  4.80887108e-02  4.88711670e-02\n",
      " -1.51377718e-03  3.87073047e-02 -6.37848005e-02  6.17341250e-02\n",
      "  2.45890673e-02 -3.56198400e-02  2.02464517e-02 -2.30437927e-02\n",
      "  1.46860238e-02  4.40294929e-02 -1.44768497e-02  4.41016294e-02\n",
      " -2.99836043e-02 -1.89271029e-02  1.41995884e-02 -2.01272313e-02\n",
      "  1.88411288e-02  2.29200162e-02  7.84008726e-02  1.50027543e-01\n",
      "  4.40679178e-05 -8.39849096e-03 -5.40325604e-02 -5.26296049e-02\n",
      "  4.59266827e-02 -3.85229811e-02  2.47734468e-02 -3.44052725e-02\n",
      "  2.00144313e-02  2.62262672e-02 -1.21491458e-02  2.49616392e-02\n",
      " -3.41597274e-02  4.26572748e-02 -1.26066674e-02  4.24032137e-02\n",
      " -6.42599957e-03  3.48495349e-04  2.95522530e-02  2.59883292e-02\n",
      " -8.23103823e-03 -3.30139138e-02 -1.86161753e-02  1.70753449e-02\n",
      " -1.15260920e-02 -1.83335729e-02  7.43192509e-02 -1.88357141e-02\n",
      " -2.92073973e-02  2.07552016e-02 -1.52894168e-03  3.80634703e-02\n",
      " -1.93638715e-03 -2.00231597e-02 -4.89075221e-02  5.94644360e-02\n",
      " -1.31816138e-02 -3.54926176e-02  8.80849198e-04 -4.55688499e-02\n",
      " -3.11200097e-02 -3.22823785e-02 -7.38825742e-03 -2.96634412e-03\n",
      "  1.58588849e-02 -1.10126920e-02  8.26921500e-03  2.51333863e-02\n",
      " -2.51738559e-02  2.63975672e-02 -6.60493895e-02  9.46769584e-03\n",
      "  3.81216332e-02 -1.39591959e-03 -1.00515664e-01  5.51170781e-02\n",
      "  1.15295034e-03  5.11957407e-02  3.66236158e-02 -1.01307500e-02\n",
      " -3.59367318e-02  3.40836588e-03  1.32816508e-02 -1.93631127e-02\n",
      "  8.96517932e-02 -2.46049538e-02 -4.88758273e-02  6.02202816e-03\n",
      " -6.36151582e-02  1.94535013e-02 -2.65742857e-02  4.48909514e-02\n",
      "  5.78704569e-03  1.56251192e-02 -1.18699158e-02 -5.31458855e-02\n",
      " -1.84104163e-02  1.50995143e-02 -1.98116489e-02 -3.85555904e-04\n",
      "  8.85322504e-03  2.37406581e-03 -6.08110614e-03 -2.16030348e-02\n",
      " -1.67107433e-02 -3.30877937e-02  1.80485435e-02 -3.41212115e-04\n",
      " -1.94067005e-02  1.04267308e-02  4.42557298e-02  3.39429341e-02\n",
      " -6.21812069e-04  1.26498714e-02  4.82963920e-02  1.72744580e-02\n",
      " -5.48558086e-02  1.01678018e-02  1.71694253e-02  2.95034349e-02\n",
      "  3.21722813e-02  3.08614895e-02 -7.96349645e-02  2.18018284e-03\n",
      "  1.10297874e-02  2.29526795e-02  7.82083161e-03  1.50608802e-02\n",
      "  5.74990269e-03 -7.65418112e-02 -4.97021377e-02  3.73053970e-03\n",
      "  6.60317624e-03  3.58332810e-03  3.55059840e-03  1.40292691e-02\n",
      " -4.81930748e-02  2.46215221e-02 -1.05600683e-02 -4.45122272e-02\n",
      " -7.24477088e-03  5.65271650e-04  1.41255762e-02 -3.65416193e-03\n",
      "  9.34036972e-04 -6.88179433e-02  3.56295705e-02  1.49929048e-02\n",
      "  4.98881377e-02 -4.47846800e-02 -1.00718383e-02  2.87540965e-02\n",
      " -3.25534306e-02 -8.84939171e-03 -2.17122231e-02 -2.26787254e-02\n",
      "  3.33230682e-02 -1.51362363e-02 -2.55323853e-02 -2.71396935e-02\n",
      "  1.35915009e-02 -8.74517392e-03 -3.70942405e-03  4.57811877e-02\n",
      " -3.03264745e-02 -1.80197638e-02  2.30746269e-02 -3.31482626e-02\n",
      "  3.18139270e-02  2.86138300e-02  6.08386397e-02 -6.01858869e-02\n",
      "  4.78289649e-02 -3.62058803e-02  3.23520303e-02 -1.87737180e-03\n",
      "  2.38084495e-02 -1.81635171e-02 -5.76227857e-03  1.69388577e-03\n",
      "  2.72811167e-02  1.30332531e-02 -9.79585797e-02  1.27858501e-02\n",
      " -9.32133291e-03 -1.79391503e-02  3.55859362e-02 -3.10662352e-02\n",
      "  1.66468136e-02 -1.10167218e-02 -3.05880904e-02 -7.12767020e-02\n",
      "  1.08948201e-01  4.41812575e-02  6.50704512e-03 -6.63082208e-03\n",
      " -3.60672846e-02  8.65119975e-03 -6.53736293e-02  2.83071306e-02\n",
      " -3.94285955e-02  3.54083348e-03  2.52810922e-02 -1.37864305e-02\n",
      " -5.24630547e-02 -2.70451128e-04  1.89849560e-03  2.55954731e-02\n",
      " -8.45676288e-03  2.95196809e-02  1.05190165e-02  3.94788524e-03\n",
      " -1.08677363e-02  7.34106824e-03 -2.78355964e-02  1.30225047e-02\n",
      " -7.06095174e-02 -7.77802954e-04 -3.47124860e-02  9.13020223e-02\n",
      " -1.49564045e-02 -2.72226427e-02  2.37389281e-02 -2.46995557e-02\n",
      " -6.51106331e-03  3.50940935e-02 -3.90953831e-02  7.42474645e-02\n",
      " -1.32327322e-02 -1.34294806e-02  4.62272391e-02  5.57316747e-03\n",
      "  5.45940809e-02  5.93404397e-02 -3.77516053e-03 -2.19446532e-02\n",
      " -2.75410749e-02 -3.94143499e-02 -1.23412898e-02  2.06630062e-02\n",
      "  5.22247367e-02  5.98741556e-03 -8.47639400e-04  5.99614996e-03\n",
      "  7.33453780e-02  7.04870094e-03  2.48644575e-02 -3.02552599e-02\n",
      "  2.74311565e-02 -5.96044352e-04 -7.20175740e-04  2.70290603e-03\n",
      "  4.86599188e-03 -3.39962505e-02 -3.06771137e-02  4.50015627e-02\n",
      "  2.41936352e-02 -5.56779560e-03  2.85301125e-03  6.41377643e-03\n",
      " -1.66585874e-02  1.83310229e-02  9.50783025e-03 -1.15563069e-02\n",
      " -7.79673085e-02  5.70371049e-03 -1.97426528e-02  4.08150554e-02\n",
      "  9.17546917e-03 -1.37584824e-02 -6.00255802e-02 -1.00901790e-01\n",
      " -1.37663763e-02  4.90421429e-02  2.80298106e-02 -1.41888112e-02\n",
      "  4.48407456e-02 -3.40478239e-03  5.69693185e-03  1.03522919e-03\n",
      "  4.48916331e-02  6.58217371e-02 -2.03032419e-02  1.98952351e-02\n",
      " -5.03985174e-02 -1.48716327e-02  1.95834264e-02  3.82582261e-03\n",
      " -1.74295250e-02 -6.72721630e-03 -6.82796864e-03 -5.94287850e-02\n",
      "  4.39023823e-02  1.67872179e-02  2.50562783e-02  5.34726046e-02\n",
      " -1.26904175e-02 -6.13533631e-02  9.21433311e-05  1.04534328e-02\n",
      "  3.15657966e-02  1.52451796e-02  3.90102863e-02  2.33941562e-02\n",
      "  5.85864298e-02 -8.60880781e-03  1.84081402e-02 -4.54071313e-02\n",
      " -1.35851456e-02  5.47225326e-02  6.19086735e-02  1.51732825e-02\n",
      "  4.50413078e-02 -5.45856431e-02 -3.50062288e-02 -3.58643755e-02\n",
      "  4.08726819e-02  3.96728255e-02  1.01952965e-03  2.55074329e-03\n",
      "  3.38263996e-02 -3.78793962e-02  3.61242369e-02  2.15313062e-02\n",
      "  1.67018324e-02 -9.77216754e-04  7.80190714e-03 -2.50508189e-02\n",
      " -3.68336998e-02 -3.17849364e-04  3.13391425e-02  9.31848865e-03\n",
      "  6.10312354e-03  4.70276363e-03 -1.26695549e-02  6.11403994e-02\n",
      " -2.79159956e-02  4.79096249e-02  2.36498844e-02 -2.17673462e-02\n",
      " -1.92667581e-02  9.55469348e-03 -8.52119923e-03 -5.41613623e-02\n",
      " -2.43023969e-02 -4.40557376e-02  1.28528029e-02 -7.77121037e-02\n",
      "  2.60586161e-02 -6.36650133e-04 -4.60047349e-02 -2.00289730e-02\n",
      " -3.63020273e-03 -3.26912012e-03 -6.91871205e-03  4.55128774e-02\n",
      " -6.95070066e-03  1.64477043e-02  6.89850822e-02 -5.24429753e-02\n",
      "  1.90982148e-02  3.26437280e-02 -1.98884569e-02  1.33171910e-02\n",
      "  3.54530066e-02  4.19051796e-02  5.48322313e-02  2.51252186e-02\n",
      "  1.29780062e-02 -4.11960110e-02 -2.18061376e-02 -2.42738854e-02\n",
      " -5.07960245e-02  1.10570621e-02 -6.38434710e-03  4.13188934e-02\n",
      "  7.49048740e-02  3.48792374e-02 -1.33983931e-02 -4.08543870e-02\n",
      "  9.34885163e-03  3.08825243e-02 -1.19532328e-02 -3.15915304e-03\n",
      " -2.36262605e-02  4.06336458e-03  1.68028120e-02 -2.14343164e-02\n",
      " -4.11795313e-03 -4.29602265e-02 -4.32029814e-02 -3.10271103e-02\n",
      " -2.48433952e-03  2.71917600e-03  3.49158682e-02  7.51900813e-03\n",
      "  2.70666387e-02  1.86019926e-03 -6.81099715e-03 -1.31690886e-03\n",
      "  7.36823399e-03 -1.79300215e-02 -5.74808605e-02 -2.86181290e-02\n",
      " -9.26372502e-03  2.48139407e-02  1.06307250e-02 -1.70344710e-02\n",
      "  6.10061688e-03 -3.60789672e-02 -1.51328072e-02 -3.31744226e-03\n",
      " -1.71410805e-03  2.59953458e-02 -1.36324642e-02  6.06083386e-02\n",
      "  1.60873309e-02 -1.99951092e-03 -1.75398774e-02  5.49402125e-02\n",
      " -8.05871338e-02  3.31995822e-02  2.24744547e-02 -5.79406926e-03\n",
      "  5.03720390e-03  2.60853171e-02 -5.97836152e-02 -5.16273826e-03\n",
      " -2.25646771e-03 -1.83061976e-02  5.80598526e-02  1.39160668e-02\n",
      "  4.36990196e-03  1.88007597e-02  1.77676193e-02  2.41344012e-02\n",
      " -1.51876351e-02 -1.70669928e-02 -4.76965420e-02 -3.23634520e-02\n",
      "  3.73654403e-02 -7.48154819e-02 -1.30310068e-02 -3.87934856e-02\n",
      "  4.57144948e-03  1.16707245e-02 -9.25392937e-03  1.54313445e-02\n",
      "  2.80709863e-02 -1.46231260e-02  1.36037171e-02 -4.05327827e-02\n",
      " -1.26854712e-02  6.98018819e-03 -3.10385483e-03 -2.91067567e-02\n",
      " -7.29747163e-03  5.84995784e-02 -3.35801370e-03  7.40199089e-02\n",
      "  5.84165156e-02 -2.36028470e-02 -8.35471228e-02 -7.80089665e-03\n",
      "  8.33637733e-03 -3.82631533e-02 -1.03936028e-02 -5.47412857e-02\n",
      "  3.26823480e-02 -2.12677140e-02 -2.03538239e-02  5.46398535e-02\n",
      " -6.09716512e-02 -1.66495447e-04  1.20872445e-02  3.78117226e-02\n",
      " -1.70037076e-02  3.49454209e-02  3.93115543e-02 -4.22452912e-02\n",
      " -4.73413914e-02 -2.93678343e-02 -6.81141838e-02  5.13469800e-03\n",
      " -8.61743558e-03  3.24567072e-02  2.44999807e-02 -6.33784756e-02\n",
      "  2.86673699e-02  5.14679998e-02  4.50974107e-02 -5.29056191e-02\n",
      "  3.61169465e-02  2.90702321e-02  2.08083298e-02 -5.93396984e-02\n",
      " -2.79677231e-02  4.71530370e-02  1.63461287e-02 -5.94210206e-03\n",
      "  1.68019664e-02  1.01210212e-03 -5.30031510e-03 -6.42710030e-02\n",
      " -4.94738407e-02 -1.60317365e-02 -6.04567155e-02 -1.37482956e-02\n",
      "  8.16733204e-03  1.01227969e-01  7.26449257e-03  4.61979024e-02\n",
      "  1.72048584e-02  1.82516407e-02 -3.79086891e-03  6.22051731e-02\n",
      " -6.01604059e-02  1.95845719e-02 -3.52186412e-02 -1.39315743e-02\n",
      " -1.41198142e-02 -4.13186699e-02 -3.87705825e-02 -4.81794924e-02]\n"
     ]
    }
   ],
   "source": [
    "print(f'Original text: \\n{products_df[\"description\"][0]}\\nEmbedding vector:')\n",
    "print(response[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbhzVEaBDYR2"
   },
   "source": [
    "## Clustering Model\n",
    "With the embeddings computed, you can use those to create categories representing similar products. Notice that the dataset you loaded is not labeled for which category each product belongs to. However, those product categories do exist the source data.\n",
    "\n",
    "You'll use a K-Means model to find similarities in the embedding vectors. Using scikit-learn, the [KMeans model](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) directly accepts an ndarray, which our embedding vectors are formatted as thanks to the helper functions!\n",
    "\n",
    "As mentioned, the sample data came from 5 product categories, so we're going to have the model learn 5 clusters. With the small dataset we're using, training the clustering model will take almost no time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "xCKth5J5aKr7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = response[1]\n",
    "kmeans = KMeans(n_clusters=5, n_init=\"auto\").fit(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlP8i8DCf1q7"
   },
   "source": [
    "Fitting the model also provides us with the predictions for the values used to train the model in the `labels_` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LSJtpHokeqtS",
    "outputId": "ce0ced9e-dd26-4d77-9948-7c2f24deacf1",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UinH9O6lgisw"
   },
   "source": [
    "We can sanity check that by calling the `predict` function directly, which is also how you'd cluster future products now that we've trained the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "p0qyf686gRtb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = kmeans.predict(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aA-o8YrNfm9A",
    "outputId": "1f99d627-2713-4f66-d5b9-8ee223b3d27f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.labels_[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RN02b-jUgWNP",
    "outputId": "d3f9ac26-fcbf-4a5b-aa86-c58949d8c89a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDo_U_JVoBK6"
   },
   "source": [
    "#### Evaluate the clusters\n",
    "Let's attach the predicted clusters to the original data and see some example products from each cluster to see how well the model performed.\n",
    "\n",
    "As a reminder, the data has 2,000 products from each of 5 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "35Je8UUExUDl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "products_df['category'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_6N0PT3hxguQ",
    "outputId": "516f6380-9fb2-47f7-d077-659689bbfae3",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "0    1589\n",
       "1    2582\n",
       "2    1726\n",
       "3    2034\n",
       "4    2069\n",
       "Name: name, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_df.groupby('category').count()['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjuXrMVFF2Oy"
   },
   "source": [
    "We can see that the model did not entirely accurately recreate the categories as there are not exactly 2,000 in each cluster. However, the performance isn't terrible for having spent about one second training.\n",
    "\n",
    "What you should also know about the input data is that it was sorted by category. Each block of 2,000 rows is one product category. Let's see how well the model predicts each of the different categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96gptzVUHguq",
    "outputId": "53a35b8a-ea06-4eef-fc55-d5d552aa9241",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 1486, 1: 359, 0: 100, 4: 45, 2: 10})\n",
      "Counter({2: 1709, 1: 203, 3: 36, 4: 27, 0: 25})\n",
      "Counter({1: 1908, 4: 54, 3: 27, 0: 7, 2: 4})\n",
      "Counter({0: 1454, 3: 470, 1: 47, 4: 29})\n",
      "Counter({4: 1914, 1: 65, 3: 15, 2: 3, 0: 3})\n"
     ]
    }
   ],
   "source": [
    "# Create named slices for easier reference\n",
    "beauty = slice(2000)\n",
    "appliance = slice(2000,4000)\n",
    "instrument = slice(4000,6000)\n",
    "pantry = slice(6000,8000)\n",
    "software = slice(8000,10000)\n",
    "\n",
    "beauty_cnts = Counter(predictions[beauty])\n",
    "appliance_cnts = Counter(predictions[appliance])\n",
    "instrument_cnts = Counter(predictions[instrument])\n",
    "pantry_cnts = Counter(predictions[pantry])\n",
    "software_cnts = Counter(predictions[software])\n",
    "\n",
    "product_pred_cnts = [beauty_cnts, appliance_cnts, instrument_cnts, pantry_cnts, software_cnts]\n",
    "for product_cnt in product_pred_cnts:\n",
    "    print(product_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuiAA6jEDyPa"
   },
   "source": [
    "With the set of predictions and the counts per category, we can now label the clusters based on the highest number of predictions. With many clustering tasks, we won't have a source of ground truth like in this example, so figuring out names for your clusters will be up to you. You'll do additional analysis of the features of the objects that are predicted to be in the same cluster by your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TRW36uWOOmCY",
    "outputId": "69577fa1-eb46-452d-834e-9a3e0cbb8499",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'all_beauty', 1: 'appliance', 2: 'instrument', 3: 'pantry', 4: 'software'}\n",
      "{3: 'all_beauty', 2: 'appliance', 1: 'instrument', 0: 'pantry', 4: 'software'}\n"
     ]
    }
   ],
   "source": [
    "def most_likely_cluster(counted_dict):\n",
    "    return max(counted_dict, key=counted_dict.get)\n",
    "\n",
    "product_category_list = ['all_beauty', 'appliance', 'instrument', 'pantry', 'software']\n",
    "\n",
    "product_clusters = []\n",
    "for product in product_pred_cnts:\n",
    "    product_clusters.append(most_likely_cluster(product))\n",
    "\n",
    "keys = [0, 1, 2, 3, 4] # simple list of index values as the products are inserted\n",
    "row_names = dict(zip(keys, product_category_list))\n",
    "cluster_map = dict(zip(product_clusters, product_category_list))\n",
    "print(row_names) # ascending alpha order\n",
    "print(cluster_map) # predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkrWATrAMA4o"
   },
   "source": [
    "Add all of that information to a new DataFrame for easier visualization. The prediction counts get added in as raw information, then we'll update row and column names to match the product categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "dfsvsDKBH_gJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "correctness_df = pd.DataFrame.from_dict(product_pred_cnts)\n",
    "correctness_df.rename(index=row_names, inplace=True)\n",
    "correctness_df.rename(columns=cluster_map, inplace=True)\n",
    "correctness_df.sort_index(axis=0, inplace=True)\n",
    "correctness_df.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "bCsHdgwiJC-C",
    "outputId": "c708a195-b4cb-48be-f95b-f328034a17b6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_beauty</th>\n",
       "      <th>appliance</th>\n",
       "      <th>instrument</th>\n",
       "      <th>pantry</th>\n",
       "      <th>software</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all_beauty</th>\n",
       "      <td>1486</td>\n",
       "      <td>10.0</td>\n",
       "      <td>359</td>\n",
       "      <td>100</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <td>36</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>203</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instrument</th>\n",
       "      <td>27</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1908</td>\n",
       "      <td>7</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pantry</th>\n",
       "      <td>470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47</td>\n",
       "      <td>1454</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>software</th>\n",
       "      <td>15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>1914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            all_beauty  appliance  instrument  pantry  software\n",
       "all_beauty        1486       10.0         359     100        45\n",
       "appliance           36     1709.0         203      25        27\n",
       "instrument          27        4.0        1908       7        54\n",
       "pantry             470        NaN          47    1454        29\n",
       "software            15        3.0          65       3      1914"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correctness_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tqy4cDdPRg_6"
   },
   "source": [
    "From this confusion matrix, we can see which categories have the most recognizable patterns of descriptions. Down the diagonal is the count of correct predictions.\n",
    "\n",
    "With this data, the model predicted software and instruments very well. Very few of those predictions were wrong. However, it also frequently confused appliances and beauty products for instruments. You can see which descriptions were confusing by selecting those products from the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instrument_category = product_clusters[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "fr0XMuedSqc4",
    "outputId": "ac65554c-0dd2-47a3-b682-77a98f554eb1",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ambu 276-000-001 Res-Cue Pump</td>\n",
       "      <td>Ambu Hand held Rescue Pump</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Vera Bradley Little Flap Hipster (Cocoa Moss) ...</td>\n",
       "      <td>Vera Bradley Little Flap Hipster Cocoa Moss</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>JE136 Antique Ring, Faux Emerald Ring, Vintage...</td>\n",
       "      <td>JE136 Antique Ring, Faux Emerald Ring, Vintage...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Hot Sweet Lovely Anime Lolita Cosplay Fancy Ne...</td>\n",
       "      <td>Height:approx.10cm from the fur tip to the ear...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ImZauberwald Peyote Mandala UV Patch 7.8 Inch ...</td>\n",
       "      <td>Handmade UV active embroidery patch. You can s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>Boyds TF Wuzzies Timothy F Wuzzle Soldier Tedd...</td>\n",
       "      <td>From Boyds Plush T.F. Wuzzies Collection Timot...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>Stunning Silver Colored Clover Shaped Clip On ...</td>\n",
       "      <td>Exquisite Clover Shaped Bracelet Charm In Silv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>Jovana 1PC New Classic Fashion Sexy Crystal Wo...</td>\n",
       "      <td>Unisex Wild design Fashion Sexy Crystal Wolf T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Bestpriceam (Tm) Infinity Love Heart Pearl Fri...</td>\n",
       "      <td>Infinity Love Heart Friendship Antique Leather...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Amazing Fashionable Silver Colored Phone Card ...</td>\n",
       "      <td>Great Silver Colored Phone Card Shaped Charm W...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>359 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   name  \\\n",
       "7                         Ambu 276-000-001 Res-Cue Pump   \n",
       "12    Vera Bradley Little Flap Hipster (Cocoa Moss) ...   \n",
       "27    JE136 Antique Ring, Faux Emerald Ring, Vintage...   \n",
       "31    Hot Sweet Lovely Anime Lolita Cosplay Fancy Ne...   \n",
       "34    ImZauberwald Peyote Mandala UV Patch 7.8 Inch ...   \n",
       "...                                                 ...   \n",
       "1980  Boyds TF Wuzzies Timothy F Wuzzle Soldier Tedd...   \n",
       "1982  Stunning Silver Colored Clover Shaped Clip On ...   \n",
       "1994  Jovana 1PC New Classic Fashion Sexy Crystal Wo...   \n",
       "1998  Bestpriceam (Tm) Infinity Love Heart Pearl Fri...   \n",
       "1999  Amazing Fashionable Silver Colored Phone Card ...   \n",
       "\n",
       "                                            description  category  \n",
       "7                            Ambu Hand held Rescue Pump         1  \n",
       "12          Vera Bradley Little Flap Hipster Cocoa Moss         1  \n",
       "27    JE136 Antique Ring, Faux Emerald Ring, Vintage...         1  \n",
       "31    Height:approx.10cm from the fur tip to the ear...         1  \n",
       "34    Handmade UV active embroidery patch. You can s...         1  \n",
       "...                                                 ...       ...  \n",
       "1980  From Boyds Plush T.F. Wuzzies Collection Timot...         1  \n",
       "1982  Exquisite Clover Shaped Bracelet Charm In Silv...         1  \n",
       "1994  Unisex Wild design Fashion Sexy Crystal Wolf T...         1  \n",
       "1998  Infinity Love Heart Friendship Antique Leather...         1  \n",
       "1999  Great Silver Colored Phone Card Shaped Charm W...         1  \n",
       "\n",
       "[359 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_df.iloc[beauty].query(f'category == {instrument_category}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZET0y5ULckg-"
   },
   "source": [
    "We can compare those descriptions with the descriptions from instruments that were correctly predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "RzuvpR7LchRe",
    "outputId": "b9c2c1c5-8d5e-426b-a4d2-8f2db1fb5975",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>Oscar Schmidt OR6CEB-O-U Acoustic Electric Res...</td>\n",
       "      <td>The OR6CE is a biscuit resonator guitar with c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>Vacuum Tube Set for Fender Bandmaster VM Head,...</td>\n",
       "      <td>(2)T-12AX7-S-JJ (1)T-6L6GC-JJ-MP (Apex Matched...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>Liverpool Double Star Drum Stick/Mallet Comb S...</td>\n",
       "      <td>Liverpool Drum Sticks Mallet / Drum Stick Combo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>Didgeridoo Store Decorative Didgeridoo Midnigh...</td>\n",
       "      <td>Didgeridoo Store Decorative Didgeridoo Midnigh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4004</th>\n",
       "      <td>WellieSTR (A Pair) Real Leather Accordion/Acco...</td>\n",
       "      <td>(A Pair) Real Leather Accordion/Accordian Bell...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>MBT Lighting PAR56 Par Can - Black</td>\n",
       "      <td>Par56 Par Can. Made by MBT Lighting.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>Blast King I49BMIC20B Female XLR to 1/4-Inch P...</td>\n",
       "      <td>Blast King MICROPHONE CABLE, FEMALE XLR TO 1/4\" P</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>Kona Guitars KA15T 10-Watt Amplifier with Buil...</td>\n",
       "      <td>Kona 10 Watt Amplifier with Built-in Tuner and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>BEHRINGER STUDIO CONDENSER MICROPHONE T-47</td>\n",
       "      <td>Vacuum Tube Condenser Microphone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>Alvarez Acoustic Guitar AD60S Dreadnought Top ...</td>\n",
       "      <td>Alvarez Acoustic Guitar AD60S Dreadnought Top ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1908 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   name  \\\n",
       "4000  Oscar Schmidt OR6CEB-O-U Acoustic Electric Res...   \n",
       "4001  Vacuum Tube Set for Fender Bandmaster VM Head,...   \n",
       "4002  Liverpool Double Star Drum Stick/Mallet Comb S...   \n",
       "4003  Didgeridoo Store Decorative Didgeridoo Midnigh...   \n",
       "4004  WellieSTR (A Pair) Real Leather Accordion/Acco...   \n",
       "...                                                 ...   \n",
       "5995                 MBT Lighting PAR56 Par Can - Black   \n",
       "5996  Blast King I49BMIC20B Female XLR to 1/4-Inch P...   \n",
       "5997  Kona Guitars KA15T 10-Watt Amplifier with Buil...   \n",
       "5998         BEHRINGER STUDIO CONDENSER MICROPHONE T-47   \n",
       "5999  Alvarez Acoustic Guitar AD60S Dreadnought Top ...   \n",
       "\n",
       "                                            description  category  \n",
       "4000  The OR6CE is a biscuit resonator guitar with c...         1  \n",
       "4001  (2)T-12AX7-S-JJ (1)T-6L6GC-JJ-MP (Apex Matched...         1  \n",
       "4002    Liverpool Drum Sticks Mallet / Drum Stick Combo         1  \n",
       "4003  Didgeridoo Store Decorative Didgeridoo Midnigh...         1  \n",
       "4004  (A Pair) Real Leather Accordion/Accordian Bell...         1  \n",
       "...                                                 ...       ...  \n",
       "5995               Par56 Par Can. Made by MBT Lighting.         1  \n",
       "5996  Blast King MICROPHONE CABLE, FEMALE XLR TO 1/4\" P         1  \n",
       "5997  Kona 10 Watt Amplifier with Built-in Tuner and...         1  \n",
       "5998                   Vacuum Tube Condenser Microphone         1  \n",
       "5999  Alvarez Acoustic Guitar AD60S Dreadnought Top ...         1  \n",
       "\n",
       "[1908 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_df.iloc[instrument].query(f'category == {instrument_category}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5Eq7F46dFwC"
   },
   "source": [
    "They don't look that similar to me, but they apparently look similar to the model at the embedding vector level!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TdQb0V_ZhelM"
   },
   "source": [
    "### Save the model\n",
    "Having the model available in the notebook is all well and good, but right now, it only lives in memory and is only accessible from within the notebook. That's not very useful. We can do better. First, let's save the model locally on the machine to prevent us from losing it during a reboot. We can use Pickle to export the model to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "A0N8P4zNnFW9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_local_file = 'model.pkl'\n",
    "with open(model_local_file, 'wb') as model_file:\n",
    "    pickle.dump(kmeans, model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBk-yuVOn1hI"
   },
   "source": [
    "At least now the model is persisted to local storage, but it's still not very available. A much better place to store it is Cloud Storage!\n",
    "\n",
    "We'll default to using a Cloud Storage bucket name based on our project ID. You can set this to any Cloud Storage bucket you have access to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "f2PUNXE1peaI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "GCS_BUCKET=f\"{MY_PROJECT}-productcluster\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "PiCCwjzmqxJJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "gcs_client = storage.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKz4sgb_prqv"
   },
   "source": [
    "The following cell will create the bucket. If you set the variable to an existing bucket, skip the following cell or it will throw an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "TgLA6OZ5pi6a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Bucket: qwiklabs-gcp-03-282f7cda83db-productcluster>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcs_client.create_bucket(GCS_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7z0HBkgLqZS2"
   },
   "source": [
    "Now we can upload the model to Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "3SwIauffopyt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket = gcs_client.get_bucket(GCS_BUCKET)\n",
    "gcs_model_path = f'PaLM_embeddings_product_cluster'\n",
    "blob = bucket.blob(f'{gcs_model_path}/{model_local_file}')\n",
    "blob.upload_from_filename(model_local_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a53AFJ1g2cDI"
   },
   "source": [
    "To reload your model for future use in a notebook, simply retrive the pickled model file from Cloud Storage, then use pickle to load it again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rEnfAYvyqJsK",
    "outputId": "d324d702-0b62-4b4b-8bee-11406aead227",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 3, 3, 3, 3, 3, 1, 3, 3], dtype=int32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(model_local_file, 'rb') as f:\n",
    "    reloaded_kmeans = pickle.load(f)\n",
    "\n",
    "reloaded_kmeans.predict(embeddings[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIANpwVHrA9W"
   },
   "source": [
    "Since we still have the original in memory, we can easily show the predictions from the reloaded model are the same as the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zdnmUELnq6IJ",
    "outputId": "8e83858a-095a-413b-9584-6701aeffb280",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 3, 3, 3, 3, 3, 1, 3, 3], dtype=int32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.predict(embeddings[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibUj5szdroPg"
   },
   "source": [
    "### Model Registry\n",
    "Being in Cloud Storage means you're going to have 11-9s of durability so you know the model won't be lost, and now you can download it in other notebooks to use.\n",
    "\n",
    "However, we can still do better!\n",
    "\n",
    "You can't use the model directly from Cloud Storage to make predictions. You'd have to spin up a notebook or other server, retrieve the model, then load the model back into memory to use it again. That's a lot of work, and it doesn't let you use this model for any kind of real-time predictions.\n",
    "\n",
    "Instead, wouldn't it be great if we could directly send embeddings to our model and not have to worry about the computing behind it? By adding the model to Model Registry, we can unlock the full power of Vertex AI to run our model at scale!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2KdI6lEs7Txy"
   },
   "source": [
    "According to the [documentation](https://cloud.google.com/vertex-ai/docs/training/exporting-model-artifacts#scikit-learn), Vertex AI expects the model to be named `model.pkl` when importing to Model Registry, which is why we named it that above. To register the model, you pass in the directory (really, key prefix) for where Model Registry can find the pickled model in Cloud Storage. You also specify a serving container image, which your model will be injected into to run on Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2FxO0LB5rzg3",
    "outputId": "66e24641-f838-4de8-d051-f6ccd1650081",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/291464288325/locations/us-central1/models/1504059339030134784/operations/3215139159744184320\n",
      "Model created. Resource name: projects/291464288325/locations/us-central1/models/1504059339030134784@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/291464288325/locations/us-central1/models/1504059339030134784@1')\n"
     ]
    }
   ],
   "source": [
    "model_display_name = 'cluster_products_using_palm'\n",
    "artifact_directory_uri = f'gs://{GCS_BUCKET}/{gcs_model_path}'\n",
    "serving_container_image = 'us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-2:latest'\n",
    "\n",
    "vai_model = aiplatform.Model.upload(\n",
    "            display_name=model_display_name,\n",
    "            artifact_uri=artifact_directory_uri,\n",
    "            serving_container_image_uri=serving_container_image)\n",
    "\n",
    "vai_model.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qs2wPuz1p6WX"
   },
   "source": [
    "Now you can easily send batch predictions to your model, or publish it to an Endpoint for real-time applications!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9Q4plQOhX87"
   },
   "source": [
    "### Use the model\n",
    "Finally, with your model no longer in danger of being lost, and being substantially more usable in Model Registry, let's turn back to our local copy of the model to predict a few more products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pI6xVO35iW52"
   },
   "source": [
    "Here are a few more cleaned-up product descriptions from the original dataset that were not included in the sample, one from each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "lnKkQhXJiMv-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_products = ['Kinetronics StaticWisk Brush-7/8',\n",
    "                'Range Kleen GE/Hotpoint Large Porcelain Drip Bowl 8\"',\n",
    "                'Game of Thrones (Theme from the HBO series) - EASY PIANO Sheet Music Single',\n",
    "                'CADBURY Chocolate Candy Bar, English Toffee, 5.4 Ounce',\n",
    "                'Star Trek: The Game Show']\n",
    "new_descriptions = ['Fine quality anti-static lens brush. Made from a special blend of soft, natural hair and a conductive fiber. To use the brush, simply sweep the lens. The brush has a resistivity of 10-1 and will dissipate any static charge and release the dust.',\n",
    "                    'Are your burner reflector bowls beyond rescue? Reasonably priced and easy to clean, replacement bowls will have your stove looking spiffy in a jiffy!',\n",
    "                    'EASY Piano version of the popular theme song from the HBO series.',\n",
    "                    'Enjoy the rich taste of premium milk chocolate with the satisfying crunch of English toffee. Make any moment more delicious with an Cadbury milk chocolate with English toffee pouch.',\n",
    "                    'Star Trek: The Game Show'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gyr9SXF6pdjM"
   },
   "source": [
    "First, generate the text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "TdaUOSTVpUeK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_embeddings = model.get_embeddings(new_descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJcr5lbxpugU"
   },
   "source": [
    "The returned embeddings are in a TextEmbedding class. Convert that to an ndarray of floats to pass to the clustering model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "W-1s10iMptBB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_embeddings_nd = np.squeeze(np.stack([embedding.values for embedding in new_embeddings if embedding is not None]))\n",
    "new_predictions = kmeans.predict(new_embeddings_nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BHA2NbvIs5JA",
    "outputId": "5a7ac7e5-c15f-4f12-ff5f-71c23339d95b",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pantry', 'pantry', 'software', 'pantry', 'pantry']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_predictions_clusters = [cluster_map[x] for x in new_predictions]\n",
    "new_predictions_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mljgw9OPuZwl"
   },
   "source": [
    "How did your model do?\n",
    "\n",
    "When I ran this, the model got 4 of 5 correct. Not bad! It confused the musical instrument category for software, which was the most likely category for it to be wrong about based on my confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-c_LhprOhPje"
   },
   "source": [
    "## Congratulations!\n",
    "\n",
    "In this lab, you've converted a set of product descriptions into a vector representation using the PaLM Embeddings model. With that contextual information, you trained a clustering model to predict the category of the product based on the description. You then persisted the model to Cloud Storage, and most powerfully, added it to Model Registry. It's now ready to use in your Vertex AI pipelines!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m117",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-6:m117"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05e05253caba4266931b2c4d35b16944": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0bb79938f69b41fe8b6976cd5bb7332d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "366467fb9a6c409e9a2d0311d93b68fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48db3d8ca8d14e0ebef708aa4a270c22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_366467fb9a6c409e9a2d0311d93b68fd",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_54169e2dbec64f20b380de669b591d34",
      "value": "100%"
     }
    },
    "54169e2dbec64f20b380de669b591d34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5797768f09414ed49d673fe0bb21573b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "639ed7d1fc2449419e9adfc1efbb9fa6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_48db3d8ca8d14e0ebef708aa4a270c22",
       "IPY_MODEL_6c6e34ee0d0a4fb69c168b9b34738a73",
       "IPY_MODEL_90cdce26d7834e9b81747b2d224e69e3"
      ],
      "layout": "IPY_MODEL_f5c46ed3021a4db9a14ea5d10dcb0615"
     }
    },
    "6c6e34ee0d0a4fb69c168b9b34738a73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0bb79938f69b41fe8b6976cd5bb7332d",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_be1a4562bfde46ae8eea31b45e3f5f7a",
      "value": 2000
     }
    },
    "90cdce26d7834e9b81747b2d224e69e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05e05253caba4266931b2c4d35b16944",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5797768f09414ed49d673fe0bb21573b",
      "value": " 2000/2000 [03:22&lt;00:00,  9.89it/s]"
     }
    },
    "be1a4562bfde46ae8eea31b45e3f5f7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f5c46ed3021a4db9a14ea5d10dcb0615": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
